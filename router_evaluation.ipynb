{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ac30319-c422-4cb2-96dd-c3e706c8857c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import requests\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "babaa2d8-76c3-4d35-b32a-24e64092c320",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_maxs(l):\n",
    "    maximum = max(l)\n",
    "    pos = []\n",
    "    for i in range(len(l)):\n",
    "        if l[i] == maximum:\n",
    "            pos.append(i)\n",
    "    return pos\n",
    "\n",
    "\n",
    "def get_mins(l):\n",
    "    minimum = min(l)\n",
    "    pos = []\n",
    "    for i in range(len(l)):\n",
    "        if l[i] == minimum:\n",
    "            pos.append(i)\n",
    "    return pos\n",
    "\n",
    "def ndcg_per_query(ranked_relevance, k):\n",
    "    if len(ranked_relevance)<k:\n",
    "        ranked_relevance_l = ranked_relevance.tolist()\n",
    "        ranked_relevance_l.extend([0 for i in range(k - len(ranked_relevance))])\n",
    "        ranked_relevance = np.array(ranked_relevance)\n",
    "    ranked_relevance = np.array(ranked_relevance)\n",
    "    ranked_relevance = ranked_relevance[:k]\n",
    "\n",
    "    dcg = 0\n",
    "    for i, rel in enumerate(ranked_relevance,start=1):\n",
    "        dcg+=(2**rel - 1)/ np.log2(i+1)\n",
    "\n",
    "    relevance_sorted = np.sort(ranked_relevance)[::-1]\n",
    "    idcg = 0\n",
    "    for i, rel in enumerate(relevance_sorted,start=1):\n",
    "        idcg+=(2**rel - 1)/ np.log2(i+1)\n",
    "\n",
    "    if idcg ==0:\n",
    "        return 0\n",
    "    else:\n",
    "        return dcg/idcg\n",
    "\n",
    "def ndcg(ranked_relevance_list, k):\n",
    "    ranked_relevance_list = np.array(ranked_relevance_list)\n",
    "    result = []\n",
    "\n",
    "\n",
    "    for ranked_relevance in ranked_relevance_list:\n",
    "        result.append(ndcg_per_query(ranked_relevance, k))\n",
    "    return np.mean(result)\n",
    "\n",
    "def mrr(ranked_relevance_list, k):\n",
    "    ranked_relevance_list = np.array(ranked_relevance_list)\n",
    "    assert len(ranked_relevance_list)>0\n",
    "    result = 0\n",
    "    valid = 0\n",
    "    for ranked_relevance in ranked_relevance_list:\n",
    "        if len(ranked_relevance) < k:\n",
    "            ranked_relevance_l = ranked_relevance.tolist()\n",
    "            ranked_relevance_l.extend([0 for i in range(k - len(ranked_relevance))])\n",
    "            ranked_relevance = np.array(ranked_relevance_l)\n",
    "        ranked_relevance = ranked_relevance[:k]\n",
    "        if max(ranked_relevance) ==0:\n",
    "            continue\n",
    "        else:\n",
    "            valid+=1\n",
    "            for i, v in enumerate(ranked_relevance):\n",
    "                if v>0:\n",
    "                    result += 1/(i+1)\n",
    "                    break\n",
    "    return result/valid if valid>0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "877ee4be-371e-44a6-ae8e-abbfaccbd571",
   "metadata": {},
   "outputs": [],
   "source": [
    "session = requests.Session()\n",
    "session.trust_env = False\n",
    "SEARCH_URL = 'http://127.0.0.1:8000/search'\n",
    "ROUTE_URL = 'http://127.0.0.1:8002/batch_route'\n",
    "\n",
    "with open('data/relevance_label.json','r',encoding='utf-8') as f:\n",
    "    relevance_label = json.loads(f.read())\n",
    "\n",
    "queries = pd.read_parquet('data/X_test.parquet').squeeze().tolist()\n",
    "query = queries[0]\n",
    "\n",
    "target = pd.read_parquet('data/y_test.parquet').squeeze().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339f865b-e359-4737-ace6-ef1f824343ff",
   "metadata": {},
   "source": [
    "For each query:\n",
    "\n",
    "   - Run BM25, Dense, and Hybrid retrieval\n",
    "\n",
    "     - Call vector-search service endpoints\n",
    "\n",
    "     - Record retrieved doc IDs and latency\n",
    "\n",
    "     - Convert retrieved docs into a relevance array, e.g. [1, 0, 0, 0, 0]\n",
    "    \n",
    "   - Select method that ranks the ground-truth answer highest\n",
    "\n",
    "   - Break ties by latency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19bd4437-92f5-4351-984b-36204a5dec3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_result = {}\n",
    "for query in queries:\n",
    "    query_result={}\n",
    "    for mode in ['bm25','dense','hybrid']:\n",
    "        query_result[mode] = {}\n",
    "        payload = {'query': query,\n",
    "                   'corpus': 'stackoverflow',\n",
    "                   'top_n': 10,\n",
    "                   'mode': mode,\n",
    "                   'rerank': False\n",
    "                   }\n",
    "        search_result = session.post(SEARCH_URL, json=payload).json()\n",
    "        result_ids = [relevance_label[query].get(r['id'], 0) for r in search_result['results']]\n",
    "        query_result[mode]['search_relevance'] = result_ids\n",
    "        query_result[mode]['latency'] = search_result['latency_seconds']\n",
    "        query_result[mode]['mrr'] = mrr([query_result[mode]['search_relevance']], 10)\n",
    "    metrics = [query_result[mode]['mrr'] for mode in ['bm25','dense','hybrid']]\n",
    "    if max(metrics) == 0:\n",
    "        print(f'NO HIT Query: {query}')\n",
    "        print(f'{query_result}')\n",
    "    else:\n",
    "        max_pos = get_maxs(metrics)\n",
    "        if len(max_pos) == 1:\n",
    "            query_result['target_method'] = max_pos[0]\n",
    "        else:\n",
    "            latencies = [query_result[mode]['latency'] for mode in ['bm25','dense','hybrid']]\n",
    "            min_latency_pos = get_mins(latencies)[0]\n",
    "            best_method = max_pos[min_latency_pos]\n",
    "            query_result['target_method'] = best_method\n",
    "        run_result[query] = query_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d0b44cfa-dafe-47c1-9378-cb97d17289d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bm25': {'search_relevance': [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'latency': 0.002997159957885742,\n",
       "  'mrr': 0.3333333333333333},\n",
       " 'dense': {'search_relevance': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'latency': 0.03401041030883789,\n",
       "  'mrr': 0},\n",
       " 'hybrid': {'search_relevance': [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'latency': 0.04207277297973633,\n",
       "  'mrr': 1.0},\n",
       " 'target_method': 2}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#example run result\n",
    "run_result[query] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08fcaaab-51a5-458c-b99c-76d5484a1ee1",
   "metadata": {},
   "source": [
    "evaluation for bm25, dense and hybrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1adea8af-58b1-4933-9ba6-1b418dbf8b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "relevance_by_mode = {}\n",
    "latencies_by_mode = {}\n",
    "for mode in ['bm25','dense','hybrid']:\n",
    "    latencies_by_mode[mode] = []\n",
    "    relevance_by_mode[mode] = []\n",
    "    for query in queries:\n",
    "        relevance_by_mode[mode].append(run_result[query][mode]['search_relevance'])\n",
    "        latencies_by_mode[mode].append(run_result[query][mode]['latency'])\n",
    "eval_by_mode = {}\n",
    "eval_latencies = {}\n",
    "for mode in ['bm25','dense','hybrid']:\n",
    "    eval_latencies[mode]=sum(latencies_by_mode[mode])/len(latencies_by_mode[mode])\n",
    "    eval_by_mode[mode]={}\n",
    "    eval_by_mode[mode]['mrr'] = mrr(relevance_by_mode[mode],10)\n",
    "    eval_by_mode[mode]['ndcg'] = ndcg(relevance_by_mode[mode],10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3198d38b-d075-4989-8219-8f9a9f22d2c4",
   "metadata": {},
   "source": [
    "get the routing result by calling the Router Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ade0e8f-d67d-4ec8-90fb-5e10a63c0c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = session.post(ROUTE_URL,json = {'queries':queries})\n",
    "route_result = result.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3c709aa4-56cb-4115-8e26-d2968cc19c82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.51\n"
     ]
    }
   ],
   "source": [
    "#accuracy\n",
    "accuracy = (np.array(route_result['route']) == np.array(target)).sum()/len(target)\n",
    "print(f'accuracy: {accuracy:0.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "391b63f4-14d6-458b-b00b-dfa76b47e8a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[51, 24, 25],\n",
       "       [19, 39, 42],\n",
       "       [ 4, 32, 64]], dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#confusion matrix\n",
    "#route likes to forecast hybrid\n",
    "confusion_matrix(target,route_result['route'],labels=['bm25','dense','hybrid'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade521b1-0b01-42e4-987a-d81afd213aba",
   "metadata": {},
   "source": [
    "evaluation for router service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c1177230-3513-473d-b8c8-8a1dfdb79971",
   "metadata": {},
   "outputs": [],
   "source": [
    "relevance_by_mode['route'] = []\n",
    "eval_by_mode['route'] = {}\n",
    "latencies_by_mode['route'] = []\n",
    "for i,query in enumerate(queries):\n",
    "    route = route_result['route'][i]\n",
    "    relevance_by_mode['route'].append(run_result[query][route]['search_relevance'])\n",
    "    latencies_by_mode['route'].append(run_result[query][route]['latency'])\n",
    "eval_by_mode['route']['mrr'] = mrr(relevance_by_mode['route'],10)\n",
    "eval_by_mode['route']['ndcg'] = ndcg(relevance_by_mode['route'],10)\n",
    "eval_latencies['route'] = sum(latencies_by_mode['route'])/len(latencies_by_mode['route'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0403b1-f6f6-4c38-ab6e-73eeb8bab1c5",
   "metadata": {},
   "source": [
    "evaluation for router"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0bcfb42d-9fa5-465c-b339-3d1ea3dcc089",
   "metadata": {},
   "outputs": [],
   "source": [
    "relevance_by_mode['oracle'] = []\n",
    "eval_by_mode['oracle'] = {}\n",
    "latencies_by_mode['oracle'] = []\n",
    "for i,query in enumerate(queries):\n",
    "    route = target[i]\n",
    "    relevance_by_mode['oracle'].append(run_result[query][route]['search_relevance'])\n",
    "    latencies_by_mode['oracle'].append(run_result[query][route]['latency'])\n",
    "eval_by_mode['oracle']['mrr'] = mrr(relevance_by_mode['oracle'],10)\n",
    "eval_by_mode['oracle']['ndcg'] = ndcg(relevance_by_mode['oracle'],10)\n",
    "eval_latencies['oracle'] = sum(latencies_by_mode['oracle'])/len(latencies_by_mode['oracle'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05c63823-488a-451e-972f-ec9773ccae3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bm25</th>\n",
       "      <th>dense</th>\n",
       "      <th>hybrid</th>\n",
       "      <th>route</th>\n",
       "      <th>oracle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mrr</th>\n",
       "      <td>0.558785</td>\n",
       "      <td>0.632364</td>\n",
       "      <td>0.722049</td>\n",
       "      <td>0.681678</td>\n",
       "      <td>0.783455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ndcg</th>\n",
       "      <td>0.531766</td>\n",
       "      <td>0.652385</td>\n",
       "      <td>0.774623</td>\n",
       "      <td>0.713863</td>\n",
       "      <td>0.836487</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          bm25     dense    hybrid     route    oracle\n",
       "mrr   0.558785  0.632364  0.722049  0.681678  0.783455\n",
       "ndcg  0.531766  0.652385  0.774623  0.713863  0.836487"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(eval_by_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c736a411-8304-4b67-9e7b-db38a87235b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bm25      0.006670\n",
       "dense     0.040926\n",
       "hybrid    0.047576\n",
       "route     0.038084\n",
       "oracle    0.034011\n",
       "dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(eval_latencies)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
